{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\atiqu\\\\OneDrive\\\\Desktop\\\\faceDetection\\\\facial-emotion-recognition\\\\emotion-recognition\\\\src\\\\App.js\",\n    _s = $RefreshSig$();\n\n// import React, { useRef, useEffect } from \"react\";\n// import \"./App.css\";\n// import logo from './logo.svg';\n// import * as tf from \"@tensorflow/tfjs\";\n// import Webcam from \"react-webcam\";\n// import { drawMesh } from \"./utilities\";\n// function App() {\n//   const webcamRef = useRef(null);\n//   const canvasRef = useRef(null);\n//   const blazeface = require('@tensorflow-models/blazeface')\n//   //  Load blazeface\n//   const runFaceDetectorModel = async () => {\n//     const model = await blazeface.load()\n//     console.log(\"FaceDetection Model is Loaded..\") \n//     setInterval(() => {\n//       detect(model);\n//     }, 100);\n//   }\n//   const detect = async (net) => {\n//     if (\n//       typeof webcamRef.current !== \"undefined\" &&\n//       webcamRef.current !== null &&\n//       webcamRef.current.video.readyState === 4\n//     ) {\n//       // Get Video Properties\n//       const video = webcamRef.current.video;\n//       const videoWidth = webcamRef.current.video.videoWidth;\n//       const videoHeight = webcamRef.current.video.videoHeight;\n//       // Set video width\n//       webcamRef.current.video.width = videoWidth;\n//       webcamRef.current.video.height = videoHeight;\n//       // Set canvas width\n//       canvasRef.current.width = videoWidth;\n//       canvasRef.current.height = videoHeight;\n//       // Make Detections\n//       const face = await net.estimateFaces(video);\n//       //console.log(face);\n//       // Websocket\n//       var socket = new WebSocket('ws://localhost:8000')\n//       var imageSrc = webcamRef.current.getScreenshot()\n//       var apiCall = {\n//         event: \"localhost:subscribe\",\n//         data: { \n//           image: imageSrc\n//         },\n//       };\n//       socket.onopen = () => socket.send(JSON.stringify(apiCall))\n//       socket.onmessage = function(event) {\n//         var pred_log = JSON.parse(event.data)\n//         document.getElementById(\"Angry\").value = Math.round(pred_log['predictions']['angry']*100)\n//         document.getElementById(\"Neutral\").value = Math.round(pred_log['predictions']['neutral']*100)\n//         document.getElementById(\"Happy\").value = Math.round(pred_log['predictions']['happy']*100)\n//         document.getElementById(\"Fear\").value = Math.round(pred_log['predictions']['fear']*100)\n//         document.getElementById(\"Surprise\").value = Math.round(pred_log['predictions']['surprise']*100)\n//         document.getElementById(\"Sad\").value = Math.round(pred_log['predictions']['sad']*100)\n//         document.getElementById(\"Disgust\").value = Math.round(pred_log['predictions']['disgust']*100)\n//         document.getElementById(\"emotion_text\").value = pred_log['emotion']\n//         // Get canvas context\n//         const ctx = canvasRef.current.getContext(\"2d\");\n//         requestAnimationFrame(()=>{drawMesh(face, pred_log, ctx)});\n//       }\n//     }\n//   };\n//   useEffect(()=>{runFaceDetectorModel()}, []);\n//   return (\n//     <div className=\"App\">\n//       <Webcam\n//           ref={webcamRef}\n//           style={{\n//             position: \"absolute\",\n//             marginLeft: \"auto\",\n//             marginRight: \"auto\",\n//             left: 0,\n//             right: 600,\n//             top:20,\n//             textAlign: \"center\",\n//             zindex: 9,\n//             width: 640,\n//             height: 480,\n//           }}\n//         />\n//         <canvas\n//           ref={canvasRef}\n//           style={{\n//             position: \"absolute\",\n//             marginLeft: \"auto\",\n//             marginRight: \"auto\",\n//             left: 0,\n//             right: 600,\n//             top:20,\n//             textAlign: \"center\",\n//             zindex: 9,\n//             width: 640,\n//             height: 480,\n//           }}\n//         />\n//       <header className=\"App-header\">\n//         <img src={logo} \n//         className=\"App-logo\" \n//         alt=\"logo\"\n//         style={{\n//           position: \"absolute\",\n//           marginLeft: \"auto\",\n//           marginRight: \"auto\",\n//           bottom:10,\n//           left: 0,\n//           right: 0,\n//           width: 150,\n//           height: 150,\n//         }}\n//         />   \n//         <div className=\"Prediction\" style={{\n//           position:\"absolute\",\n//           right:100,\n//           width:500,\n//           top: 60\n//         }}>\n//           <label forhtml=\"Angry\" style={{color:'red'}}>Angry </label>\n//           <progress id=\"Angry\" value=\"0\" max = \"100\" >10%</progress>\n//           <br></br>\n//           <br></br>\n//           <label forhtml=\"Neutral\" style={{color:'lightgreen'}}>Neutral </label>\n//           <progress id=\"Neutral\" value=\"0\" max = \"100\">10%</progress>\n//           <br></br>\n//           <br></br>\n//           <label forhtml=\"Happy\" style={{color:'orange'}}>Happy </label>\n//           <progress id=\"Happy\" value=\"0\" max = \"100\" >10%</progress>\n//           <br></br>\n//           <br></br>\n//           <label forhtml=\"Fear\" style={{color:'lightblue'}}>Fear </label>\n//           <progress id=\"Fear\" value=\"0\" max = \"100\" >10%</progress>\n//           <br></br>\n//           <br></br>\n//           <label forhtml=\"Surprise\" style={{color:'yellow'}}>Surprised </label>\n//           <progress id=\"Surprise\" value=\"0\" max = \"100\" >10%</progress>\n//           <br></br>\n//           <br></br>\n//           <label forhtml=\"Sad\" style={{color:'gray'}} >Sad </label>\n//           <progress id=\"Sad\" value=\"0\" max = \"100\" >10%</progress>\n//           <br></br>\n//           <br></br>\n//           <label forhtml=\"Disgust\" style={{color:'pink'}} >Disgusted </label>\n//           <progress id=\"Disgust\" value=\"0\" max = \"100\" >10%</progress>\n//         </div>\n//         <input id=\"emotion_text\" name=\"emotion_text\" vale=\"Neutral\"\n//                style={{\n//                  position:\"absolute\",\n//                  width:200,\n//                  height:50,\n//                  bottom:60,\n//                  left:300,\n//                  \"font-size\": \"30px\",\n//                }}></input>\n//       </header>\n//     </div>\n//   );\n// }\n// export default App;\nimport React, { useRef, useEffect } from \"react\";\nimport Webcam from \"react-webcam\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\n\nfunction App() {\n  _s();\n\n  const webcamRef = useRef(null);\n  const canvasRef = useRef(null); // Function to draw the face bounding box\n\n  const drawBoundingBox = (ctx, bbox) => {\n    bbox.forEach(box => {\n      const {\n        x,\n        y,\n        w,\n        h\n      } = box;\n      ctx.beginPath();\n      ctx.lineWidth = \"4\";\n      ctx.strokeStyle = \"green\";\n      ctx.rect(x, y, w, h);\n      ctx.stroke();\n    });\n  }; // Function to detect emotions and face bounding box\n\n\n  const detect = async () => {\n    if (webcamRef.current && webcamRef.current.video.readyState === 4) {\n      const video = webcamRef.current.video;\n      const imageSrc = webcamRef.current.getScreenshot(); // WebSocket connection\n\n      const socket = new WebSocket(\"ws://localhost:8000\");\n      const apiCall = {\n        event: \"localhost:subscribe\",\n        data: {\n          image: imageSrc\n        }\n      };\n\n      socket.onopen = () => socket.send(JSON.stringify(apiCall));\n\n      socket.onmessage = event => {\n        const pred_log = JSON.parse(event.data);\n\n        if (!pred_log.error) {\n          // Update emotion progress bars\n          Object.keys(pred_log.predictions).forEach(emotion => {\n            document.getElementById(emotion).value = Math.round(pred_log.predictions[emotion] * 100);\n          }); // Display the most dominant emotion\n\n          document.getElementById(\"emotion_text\").value = pred_log.emotion; // Draw bounding box for faces\n\n          const ctx = canvasRef.current.getContext(\"2d\");\n          ctx.clearRect(0, 0, canvasRef.current.width, canvasRef.current.height); // Clear previous frame\n\n          drawBoundingBox(ctx, pred_log.bbox);\n        }\n      };\n    }\n  };\n\n  useEffect(() => {\n    const intervalId = setInterval(() => detect(), 1000); // Run detection every second\n\n    return () => clearInterval(intervalId); // Cleanup interval on unmount\n  }, []);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"App\",\n    children: [/*#__PURE__*/_jsxDEV(Webcam, {\n      ref: webcamRef,\n      screenshotFormat: \"image/jpeg\",\n      style: {\n        width: 640,\n        height: 480\n      }\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 238,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"canvas\", {\n      ref: canvasRef,\n      style: {\n        width: 640,\n        height: 480\n      }\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 243,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      children: [/*#__PURE__*/_jsxDEV(\"label\", {\n        htmlFor: \"Angry\",\n        children: \"Angry\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 245,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"progress\", {\n        id: \"Angry\",\n        max: \"100\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 246,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"label\", {\n        htmlFor: \"Happy\",\n        children: \"Happy\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 247,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"progress\", {\n        id: \"Happy\",\n        max: \"100\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 248,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"input\", {\n        id: \"emotion_text\",\n        value: \"Neutral\",\n        readOnly: true\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 249,\n        columnNumber: 9\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 244,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 237,\n    columnNumber: 5\n  }, this);\n}\n\n_s(App, \"v4cpjlVQ0JCDZnPWaD3Z9DHNiTM=\");\n\n_c = App;\nexport default App;\n\nvar _c;\n\n$RefreshReg$(_c, \"App\");","map":{"version":3,"sources":["C:/Users/atiqu/OneDrive/Desktop/faceDetection/facial-emotion-recognition/emotion-recognition/src/App.js"],"names":["React","useRef","useEffect","Webcam","App","webcamRef","canvasRef","drawBoundingBox","ctx","bbox","forEach","box","x","y","w","h","beginPath","lineWidth","strokeStyle","rect","stroke","detect","current","video","readyState","imageSrc","getScreenshot","socket","WebSocket","apiCall","event","data","image","onopen","send","JSON","stringify","onmessage","pred_log","parse","error","Object","keys","predictions","emotion","document","getElementById","value","Math","round","getContext","clearRect","width","height","intervalId","setInterval","clearInterval"],"mappings":";;;AAAA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAGA,OAAOA,KAAP,IAAgBC,MAAhB,EAAwBC,SAAxB,QAAyC,OAAzC;AACA,OAAOC,MAAP,MAAmB,cAAnB;;;AAEA,SAASC,GAAT,GAAe;AAAA;;AACb,QAAMC,SAAS,GAAGJ,MAAM,CAAC,IAAD,CAAxB;AACA,QAAMK,SAAS,GAAGL,MAAM,CAAC,IAAD,CAAxB,CAFa,CAIb;;AACA,QAAMM,eAAe,GAAG,CAACC,GAAD,EAAMC,IAAN,KAAe;AACrCA,IAAAA,IAAI,CAACC,OAAL,CAAcC,GAAD,IAAS;AACpB,YAAM;AAAEC,QAAAA,CAAF;AAAKC,QAAAA,CAAL;AAAQC,QAAAA,CAAR;AAAWC,QAAAA;AAAX,UAAiBJ,GAAvB;AACAH,MAAAA,GAAG,CAACQ,SAAJ;AACAR,MAAAA,GAAG,CAACS,SAAJ,GAAgB,GAAhB;AACAT,MAAAA,GAAG,CAACU,WAAJ,GAAkB,OAAlB;AACAV,MAAAA,GAAG,CAACW,IAAJ,CAASP,CAAT,EAAYC,CAAZ,EAAeC,CAAf,EAAkBC,CAAlB;AACAP,MAAAA,GAAG,CAACY,MAAJ;AACD,KAPD;AAQD,GATD,CALa,CAgBb;;;AACA,QAAMC,MAAM,GAAG,YAAY;AACzB,QAAIhB,SAAS,CAACiB,OAAV,IAAqBjB,SAAS,CAACiB,OAAV,CAAkBC,KAAlB,CAAwBC,UAAxB,KAAuC,CAAhE,EAAmE;AACjE,YAAMD,KAAK,GAAGlB,SAAS,CAACiB,OAAV,CAAkBC,KAAhC;AACA,YAAME,QAAQ,GAAGpB,SAAS,CAACiB,OAAV,CAAkBI,aAAlB,EAAjB,CAFiE,CAIjE;;AACA,YAAMC,MAAM,GAAG,IAAIC,SAAJ,CAAc,qBAAd,CAAf;AACA,YAAMC,OAAO,GAAG;AACdC,QAAAA,KAAK,EAAE,qBADO;AAEdC,QAAAA,IAAI,EAAE;AAAEC,UAAAA,KAAK,EAAEP;AAAT;AAFQ,OAAhB;;AAKAE,MAAAA,MAAM,CAACM,MAAP,GAAgB,MAAMN,MAAM,CAACO,IAAP,CAAYC,IAAI,CAACC,SAAL,CAAeP,OAAf,CAAZ,CAAtB;;AAEAF,MAAAA,MAAM,CAACU,SAAP,GAAoBP,KAAD,IAAW;AAC5B,cAAMQ,QAAQ,GAAGH,IAAI,CAACI,KAAL,CAAWT,KAAK,CAACC,IAAjB,CAAjB;;AAEA,YAAI,CAACO,QAAQ,CAACE,KAAd,EAAqB;AACnB;AACAC,UAAAA,MAAM,CAACC,IAAP,CAAYJ,QAAQ,CAACK,WAArB,EAAkCjC,OAAlC,CAA2CkC,OAAD,IAAa;AACrDC,YAAAA,QAAQ,CAACC,cAAT,CAAwBF,OAAxB,EAAiCG,KAAjC,GAAyCC,IAAI,CAACC,KAAL,CAAWX,QAAQ,CAACK,WAAT,CAAqBC,OAArB,IAAgC,GAA3C,CAAzC;AACD,WAFD,EAFmB,CAMnB;;AACAC,UAAAA,QAAQ,CAACC,cAAT,CAAwB,cAAxB,EAAwCC,KAAxC,GAAgDT,QAAQ,CAACM,OAAzD,CAPmB,CASnB;;AACA,gBAAMpC,GAAG,GAAGF,SAAS,CAACgB,OAAV,CAAkB4B,UAAlB,CAA6B,IAA7B,CAAZ;AACA1C,UAAAA,GAAG,CAAC2C,SAAJ,CAAc,CAAd,EAAiB,CAAjB,EAAoB7C,SAAS,CAACgB,OAAV,CAAkB8B,KAAtC,EAA6C9C,SAAS,CAACgB,OAAV,CAAkB+B,MAA/D,EAXmB,CAWqD;;AACxE9C,UAAAA,eAAe,CAACC,GAAD,EAAM8B,QAAQ,CAAC7B,IAAf,CAAf;AACD;AACF,OAjBD;AAkBD;AACF,GAjCD;;AAmCAP,EAAAA,SAAS,CAAC,MAAM;AACd,UAAMoD,UAAU,GAAGC,WAAW,CAAC,MAAMlC,MAAM,EAAb,EAAiB,IAAjB,CAA9B,CADc,CACwC;;AACtD,WAAO,MAAMmC,aAAa,CAACF,UAAD,CAA1B,CAFc,CAE0B;AACzC,GAHQ,EAGN,EAHM,CAAT;AAKA,sBACE;AAAK,IAAA,SAAS,EAAC,KAAf;AAAA,4BACE,QAAC,MAAD;AACE,MAAA,GAAG,EAAEjD,SADP;AAEE,MAAA,gBAAgB,EAAC,YAFnB;AAGE,MAAA,KAAK,EAAE;AAAE+C,QAAAA,KAAK,EAAE,GAAT;AAAcC,QAAAA,MAAM,EAAE;AAAtB;AAHT;AAAA;AAAA;AAAA;AAAA,YADF,eAME;AAAQ,MAAA,GAAG,EAAE/C,SAAb;AAAwB,MAAA,KAAK,EAAE;AAAE8C,QAAAA,KAAK,EAAE,GAAT;AAAcC,QAAAA,MAAM,EAAE;AAAtB;AAA/B;AAAA;AAAA;AAAA;AAAA,YANF,eAOE;AAAA,8BACE;AAAO,QAAA,OAAO,EAAC,OAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cADF,eAEE;AAAU,QAAA,EAAE,EAAC,OAAb;AAAqB,QAAA,GAAG,EAAC;AAAzB;AAAA;AAAA;AAAA;AAAA,cAFF,eAGE;AAAO,QAAA,OAAO,EAAC,OAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAHF,eAIE;AAAU,QAAA,EAAE,EAAC,OAAb;AAAqB,QAAA,GAAG,EAAC;AAAzB;AAAA;AAAA;AAAA;AAAA,cAJF,eAKE;AAAO,QAAA,EAAE,EAAC,cAAV;AAAyB,QAAA,KAAK,EAAC,SAA/B;AAAyC,QAAA,QAAQ;AAAjD;AAAA;AAAA;AAAA;AAAA,cALF;AAAA;AAAA;AAAA;AAAA;AAAA,YAPF;AAAA;AAAA;AAAA;AAAA;AAAA,UADF;AAiBD;;GA1EQjD,G;;KAAAA,G;AA4ET,eAAeA,GAAf","sourcesContent":["// import React, { useRef, useEffect } from \"react\";\r\n// import \"./App.css\";\r\n// import logo from './logo.svg';\r\n\r\n// import * as tf from \"@tensorflow/tfjs\";\r\n// import Webcam from \"react-webcam\";\r\n// import { drawMesh } from \"./utilities\";\r\n\r\n// function App() {\r\n//   const webcamRef = useRef(null);\r\n//   const canvasRef = useRef(null);\r\n//   const blazeface = require('@tensorflow-models/blazeface')\r\n\r\n//   //  Load blazeface\r\n//   const runFaceDetectorModel = async () => {\r\n\r\n//     const model = await blazeface.load()\r\n//     console.log(\"FaceDetection Model is Loaded..\") \r\n//     setInterval(() => {\r\n//       detect(model);\r\n//     }, 100);\r\n \r\n//   }\r\n\r\n//   const detect = async (net) => {\r\n//     if (\r\n//       typeof webcamRef.current !== \"undefined\" &&\r\n//       webcamRef.current !== null &&\r\n//       webcamRef.current.video.readyState === 4\r\n//     ) {\r\n//       // Get Video Properties\r\n//       const video = webcamRef.current.video;\r\n//       const videoWidth = webcamRef.current.video.videoWidth;\r\n//       const videoHeight = webcamRef.current.video.videoHeight;\r\n\r\n//       // Set video width\r\n//       webcamRef.current.video.width = videoWidth;\r\n//       webcamRef.current.video.height = videoHeight;\r\n\r\n//       // Set canvas width\r\n//       canvasRef.current.width = videoWidth;\r\n//       canvasRef.current.height = videoHeight;\r\n\r\n//       // Make Detections\r\n//       const face = await net.estimateFaces(video);\r\n//       //console.log(face);\r\n\r\n//       // Websocket\r\n//       var socket = new WebSocket('ws://localhost:8000')\r\n//       var imageSrc = webcamRef.current.getScreenshot()\r\n//       var apiCall = {\r\n//         event: \"localhost:subscribe\",\r\n//         data: { \r\n//           image: imageSrc\r\n//         },\r\n//       };\r\n//       socket.onopen = () => socket.send(JSON.stringify(apiCall))\r\n//       socket.onmessage = function(event) {\r\n//         var pred_log = JSON.parse(event.data)\r\n//         document.getElementById(\"Angry\").value = Math.round(pred_log['predictions']['angry']*100)\r\n//         document.getElementById(\"Neutral\").value = Math.round(pred_log['predictions']['neutral']*100)\r\n//         document.getElementById(\"Happy\").value = Math.round(pred_log['predictions']['happy']*100)\r\n//         document.getElementById(\"Fear\").value = Math.round(pred_log['predictions']['fear']*100)\r\n//         document.getElementById(\"Surprise\").value = Math.round(pred_log['predictions']['surprise']*100)\r\n//         document.getElementById(\"Sad\").value = Math.round(pred_log['predictions']['sad']*100)\r\n//         document.getElementById(\"Disgust\").value = Math.round(pred_log['predictions']['disgust']*100)\r\n\r\n//         document.getElementById(\"emotion_text\").value = pred_log['emotion']\r\n\r\n//         // Get canvas context\r\n//         const ctx = canvasRef.current.getContext(\"2d\");\r\n//         requestAnimationFrame(()=>{drawMesh(face, pred_log, ctx)});\r\n//       }\r\n//     }\r\n//   };\r\n\r\n//   useEffect(()=>{runFaceDetectorModel()}, []);\r\n//   return (\r\n//     <div className=\"App\">\r\n//       <Webcam\r\n//           ref={webcamRef}\r\n//           style={{\r\n//             position: \"absolute\",\r\n//             marginLeft: \"auto\",\r\n//             marginRight: \"auto\",\r\n//             left: 0,\r\n//             right: 600,\r\n//             top:20,\r\n//             textAlign: \"center\",\r\n//             zindex: 9,\r\n//             width: 640,\r\n//             height: 480,\r\n//           }}\r\n//         />\r\n\r\n//         <canvas\r\n//           ref={canvasRef}\r\n//           style={{\r\n//             position: \"absolute\",\r\n//             marginLeft: \"auto\",\r\n//             marginRight: \"auto\",\r\n//             left: 0,\r\n//             right: 600,\r\n//             top:20,\r\n//             textAlign: \"center\",\r\n//             zindex: 9,\r\n//             width: 640,\r\n//             height: 480,\r\n//           }}\r\n//         />\r\n//       <header className=\"App-header\">\r\n//         <img src={logo} \r\n//         className=\"App-logo\" \r\n//         alt=\"logo\"\r\n//         style={{\r\n//           position: \"absolute\",\r\n//           marginLeft: \"auto\",\r\n//           marginRight: \"auto\",\r\n//           bottom:10,\r\n//           left: 0,\r\n//           right: 0,\r\n//           width: 150,\r\n//           height: 150,\r\n//         }}\r\n//         />   \r\n//         <div className=\"Prediction\" style={{\r\n//           position:\"absolute\",\r\n//           right:100,\r\n//           width:500,\r\n//           top: 60\r\n//         }}>\r\n//           <label forhtml=\"Angry\" style={{color:'red'}}>Angry </label>\r\n//           <progress id=\"Angry\" value=\"0\" max = \"100\" >10%</progress>\r\n//           <br></br>\r\n//           <br></br>\r\n//           <label forhtml=\"Neutral\" style={{color:'lightgreen'}}>Neutral </label>\r\n//           <progress id=\"Neutral\" value=\"0\" max = \"100\">10%</progress>\r\n//           <br></br>\r\n//           <br></br>\r\n//           <label forhtml=\"Happy\" style={{color:'orange'}}>Happy </label>\r\n//           <progress id=\"Happy\" value=\"0\" max = \"100\" >10%</progress>\r\n//           <br></br>\r\n//           <br></br>\r\n//           <label forhtml=\"Fear\" style={{color:'lightblue'}}>Fear </label>\r\n//           <progress id=\"Fear\" value=\"0\" max = \"100\" >10%</progress>\r\n//           <br></br>\r\n//           <br></br>\r\n//           <label forhtml=\"Surprise\" style={{color:'yellow'}}>Surprised </label>\r\n//           <progress id=\"Surprise\" value=\"0\" max = \"100\" >10%</progress>\r\n//           <br></br>\r\n//           <br></br>\r\n//           <label forhtml=\"Sad\" style={{color:'gray'}} >Sad </label>\r\n//           <progress id=\"Sad\" value=\"0\" max = \"100\" >10%</progress>\r\n//           <br></br>\r\n//           <br></br>\r\n//           <label forhtml=\"Disgust\" style={{color:'pink'}} >Disgusted </label>\r\n//           <progress id=\"Disgust\" value=\"0\" max = \"100\" >10%</progress>\r\n//         </div>\r\n//         <input id=\"emotion_text\" name=\"emotion_text\" vale=\"Neutral\"\r\n//                style={{\r\n//                  position:\"absolute\",\r\n//                  width:200,\r\n//                  height:50,\r\n//                  bottom:60,\r\n//                  left:300,\r\n//                  \"font-size\": \"30px\",\r\n//                }}></input>\r\n//       </header>\r\n//     </div>\r\n//   );\r\n// }\r\n\r\n// export default App;\r\n\r\n\r\nimport React, { useRef, useEffect } from \"react\";\r\nimport Webcam from \"react-webcam\";\r\n\r\nfunction App() {\r\n  const webcamRef = useRef(null);\r\n  const canvasRef = useRef(null);\r\n\r\n  // Function to draw the face bounding box\r\n  const drawBoundingBox = (ctx, bbox) => {\r\n    bbox.forEach((box) => {\r\n      const { x, y, w, h } = box;\r\n      ctx.beginPath();\r\n      ctx.lineWidth = \"4\";\r\n      ctx.strokeStyle = \"green\";\r\n      ctx.rect(x, y, w, h);\r\n      ctx.stroke();\r\n    });\r\n  };\r\n\r\n  // Function to detect emotions and face bounding box\r\n  const detect = async () => {\r\n    if (webcamRef.current && webcamRef.current.video.readyState === 4) {\r\n      const video = webcamRef.current.video;\r\n      const imageSrc = webcamRef.current.getScreenshot();\r\n\r\n      // WebSocket connection\r\n      const socket = new WebSocket(\"ws://localhost:8000\");\r\n      const apiCall = {\r\n        event: \"localhost:subscribe\",\r\n        data: { image: imageSrc },\r\n      };\r\n\r\n      socket.onopen = () => socket.send(JSON.stringify(apiCall));\r\n\r\n      socket.onmessage = (event) => {\r\n        const pred_log = JSON.parse(event.data);\r\n\r\n        if (!pred_log.error) {\r\n          // Update emotion progress bars\r\n          Object.keys(pred_log.predictions).forEach((emotion) => {\r\n            document.getElementById(emotion).value = Math.round(pred_log.predictions[emotion] * 100);\r\n          });\r\n\r\n          // Display the most dominant emotion\r\n          document.getElementById(\"emotion_text\").value = pred_log.emotion;\r\n\r\n          // Draw bounding box for faces\r\n          const ctx = canvasRef.current.getContext(\"2d\");\r\n          ctx.clearRect(0, 0, canvasRef.current.width, canvasRef.current.height); // Clear previous frame\r\n          drawBoundingBox(ctx, pred_log.bbox);\r\n        }\r\n      };\r\n    }\r\n  };\r\n\r\n  useEffect(() => {\r\n    const intervalId = setInterval(() => detect(), 1000); // Run detection every second\r\n    return () => clearInterval(intervalId); // Cleanup interval on unmount\r\n  }, []);\r\n\r\n  return (\r\n    <div className=\"App\">\r\n      <Webcam\r\n        ref={webcamRef}\r\n        screenshotFormat=\"image/jpeg\"\r\n        style={{ width: 640, height: 480 }}\r\n      />\r\n      <canvas ref={canvasRef} style={{ width: 640, height: 480 }} />\r\n      <div>\r\n        <label htmlFor=\"Angry\">Angry</label>\r\n        <progress id=\"Angry\" max=\"100\"></progress>\r\n        <label htmlFor=\"Happy\">Happy</label>\r\n        <progress id=\"Happy\" max=\"100\"></progress>\r\n        <input id=\"emotion_text\" value=\"Neutral\" readOnly />\r\n      </div>\r\n    </div>\r\n  );\r\n}\r\n\r\nexport default App;\r\n"]},"metadata":{},"sourceType":"module"}